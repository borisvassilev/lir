---
title: 'Reproducible computing with `lire`'
author: Boris Vassilev
bibliography: lire.bib
version: 0.1
rights: (c) 2015 Boris Vassilev, University of Helsinki
...

# Introduction
This is a collection of tools that support programming language-agnostic reproducible computing.

This document is self-hosting: the implementation presented here can be used to produce the final human-readable documentation.
This means that at any point it only implements enough to be able to compile itself.

The following bootstrapping script can be extracted and run as follows:

~~~
$ notangle -R"bootstrap" lire.lir > bootstrap.sh
$ chmod u+x bootrstrap.sh
$ ./bootstrap.sh
~~~

Running this will extract and install the `lire` executable and tools.
From there on, `lire` can be used to generate the documentation.

<<bootstrap>>=
<<Bash shebang>>

notangle -R"lir-pandoc" -filter emptydefn lire.lir > lir-pandoc
chmod u+x lir-pandoc
echo "tangled lir-pandoc"

notangle -R"nwpipe-pandoc.pl" -filter emptydefn lire.lir > nwpipe-pandoc.pl
swipl --goal=main -o nwpipe-pandoc -c nwpipe-pandoc.pl
echo "tangled and compiled nwpipe-pandoc.pl"

./lir-pandoc lire.lir > lire.pandoc
echo "converted to pandoc"

pandoc --filter pandoc-citeproc \
	--to=html5 \
	--standalone --css=lire.css --smart \
	-o lire.html lire.pandoc
echo "used pandoc to compile to html"
@

# The Back End
In its first version, it consist only of a [Pandoc](http://johnmacfarlane.net/pandoc/) back end for [Noweb](https://www.cs.tufts.edu/~nr/noweb/) [@Noweb2008].
The back end reads from standard input the pipeline representation emitted by Noweb's `markup` and writes to standard output a document in Pandoc's markdown.
It assumes that all documentation chunks in the source document are written in Pandoc's markdown.
The code chunks in the source document are represented as fenced code blocks preceded by a level-three Atx-style header with the name of the code chunk and followed by a single horizontal rule.

This script uses `markup` provided by `noweb`, and passes the output to the back end that transform `noweb`'s pipeline to Pandoc's markdown.
<<lir-pandoc>>=
<<Bash shebang>>
<<`Noweb` location>>/markup "$@" \
	| <<`Noweb` location>>/emptydefn \
	| ./nwpipe-pandoc
@

Logically, the back end can be broken down to components, each taking care of one of the following:

- Reading each _token_ in `noweb`'s pipeline representation from standard input and parsing it, to obtain an equivalent Prolog term -- [[<<Parse `noweb` tokens>>]];
- A finite state machine that consumes the Prolog terms and emits Pandoc markdown -- [[<<Pipeline FSM>>]] (it is rather a finite state transducer, as it generates output, but let's not get too formal);
- A writer that transforms each term to the actual emitted markdown -- [[<<Emit Pandoc's markdown>>]].

The program defines a [[main/0]] so that it can be compiled and run as a command line tool.
<<nwpipe-pandoc.pl>>=
:- set_prolog_flag(verbose, silent). % no messages of type `informational` or `banner`

main :-
	current_prolog_flag(argv, Argv), % get command line arguments
	prompt(_Old, ''), %  turn off prompt
	nwpipeline_to_pandoc(Argv),
	halt. % exit with success
main :-
	halt(1). % otherwise, exit with failure (1)

nwpipeline_to_pandoc(_) :- % command line arguments ignored TODO
	nwpipeline_fsm.

<<Parse `noweb` tokens>>
<<Pipeline FSM>>
<<Emit Pandoc's markdown>>
@

## Parsing `noweb` tokens
The first component reads the line-oriented pipeline representation of `noweb` from standard input and turns each line (token) into a Prolog term.
<<Parse `noweb` tokens>>=
<<Read lines from standard input>>
<<`Noweb` tokens $\rightarrow$ prolog terms>>
@

To read lines from standard input we define [[next_input/1]] that unifies its argument with the Prolog term representing the next `noweb` token, or `end_of_file` at the end of input.
<<Read lines from standard input>>=
:- use_module(library(readutil), [read_line_to_codes/2]).
next_input(T) :-
	read_line_to_codes(user_input, Codes),
	nwtoken_to_plterm(Codes, T).

nwtoken_to_plterm(end_of_file, end_of_file).
nwtoken_to_plterm([0'@|Token], T) :-
	phrase(token_term(T), Token).
@

The structure of the Prolog terms mostly mirrors the structure of the tokens as described in "The `noweb` Hacker's Guide" [@Ramsey1992].
In the table [[nwtoken/3]], the first argument is `noweb`'s keyword, the second argument represents the items in this token, and the third argument is the resulting Prolog term.
<<`Noweb` tokens $\rightarrow$ prolog terms>>=
% Tagging keywords
nwtoken(file, [space, atom_rest(File)], file(File)).
% Structural keywords
nwtoken(begin, [space, chunk_kind(Kind), space, integer(N)], begin(Kind, N)).
nwtoken(end, [space, chunk_kind(Kind), space, integer(N)], end(Kind, N)).
nwtoken(text, [space, string_rest(Text)], text(Text)).
nwtoken(nl, [], nl).
nwtoken(defn, [space, string_rest(Name)], defn(Name)).
nwtoken(use, [space, string_rest(Name)], use(Name)).
nwtoken(quote, [], quote).
nwtoken(endquote, [], endquote).

<<Interpreter>>
@

This approach of using a table containing a miniature program in the second argument and implementing an interpreter for it is directly borrowed from the chapter on definite clause grammer in "The Craft of Prolog" [@OKeefe1990, pp. 299-300].
Here is the interpreter:
<<Interpreter>>=
token_term(T) -->
	nonblanks(NB),
	{	atom_codes(Keyword, NB),
		nwtoken(Keyword, Items, T)
	},
	nwtokenitems(Items).

nwtokenitems([]) --> [].
nwtokenitems([I|Is]) -->
	nwtokenitem(I),
	nwtokenitems(Is).

<<Transform individual items>>
@

Here we define the transformation for each item appearing in [[nwtoken/3]]:
<<Transform individual items>>=
:- use_module(library(dcg/basics), [nonblanks//1, integer//1]).
nwtokenitem(atom_rest(A)) -->
	rest(Codes),
	{	atom_codes(A, Codes)
	}.
nwtokenitem(space) -->
	[0'\s]. % could it be another "white"?...
nwtokenitem(integer(N)) -->
	integer(N).
nwtokenitem(string_rest(Str)) -->
	rest(Codes),
	{	string_codes(Str, Codes)
	}.
nwtokenitem(chunk_kind(CK)) -->
	nonblanks(Codes),
	{	atom_codes(CK, Codes),
		nwchunk_kind(CK)
	}.

rest([]) --> [].
rest([C|Cs]) -->
	[C],
	rest(Cs).

nwchunk_kind(code).
nwchunk_kind(docs).
@

## Pipeline Finite State Machine
To represent a finite state machine in Prolog we use predicates for states and predicate clauses for arcs (transitions), another idea borrowed from "The Craft of Prolog" [@OKeefe1990, pp. 353].
The finite state machine is initialized by [[nwpipeline_fsm/0]].
The input to the state machine are the terms representing the `noweb` tokens, obtained by consecutive calls to [[next_input/1]].
<<Pipeline FSM>>=
nwpipeline_fsm :-
	next_input(T),
	start(T).
% States
<<Start>>
<<File>>
<<Begin chunk>>
<<Docs chunk>>
<<Quoted code>>
<<Code chunk>>
% etc
@

The pipeline representation consists of one or more files:
<<Start>>=
start(file(_File)) :-
	next_input(T),
	file(T).
@

<<File>>=
file(begin(Kind, N)) :-
	begin_chunk(Kind, N).
file(file(_File)) :-
	next_input(T),
	file(T).
file(end_of_file).
@

This is not a real state, since the transition happens without any input.
<<Begin chunk>>=
begin_chunk(docs, N) :-
	next_input(T),
	docs(T, N).
begin_chunk(code, N) :-
	next_input(T),
	code(T, N, Content, Content).
@

Since the documentation chunks are expected to be valid Pandoc markdown, the contents are simply emitted unchanged to the output.
<<Docs chunk>>=
docs(end(docs, N), N) :-
	next_input(T),
	file(T).
docs(nl, N) :-
	nl,
	next_input(T),
	docs(T, N).
docs(text(Text), N) :-
	format("~s", [Text]),
	next_input(T),
	docs(T, N).
docs(quote, N) :-
	next_input(T),
	quote(T, N, Content, Content).
@

For both quoted (inline) code and code chunks, the contents are first collected before emitted at the end of the quote or code chunk.
<<Quoted code>>=
quote(endquote, N, Content, []) :-
	emit(quote(Content)),
	next_input(T),
	docs(T, N).
quote(text(Text), N, Content, [text(Text)|Rest]) :-
	next_input(T),
	quote(T, N, Content, Rest).
quote(nl, N, Content, [nl|Rest]) :-
	next_input(T),
	quote(T, N, Content, Rest).
quote(use(Name), N, Content, [use(Name)|Rest]) :-
	next_input(T),
	quote(T, N, Content, Rest).

<<Code chunk>>=
code(end(code, N), N, Content, []) :-
	emit(code(Content)),
	next_input(T),
	file(T).
code(defn(Name), N, Content, [defn(Name)|Rest]) :-
	next_input(T),
	code(T, N, Content, Rest).
code(use(Name), N, Content, [use(Name)|Rest]) :-
	next_input(T),
	code(T, N, Content, Rest).
code(nl, N, Content, [nl|Rest]) :-
	next_input(T),
	code(T, N, Content, Rest).
code(text(Text), N, Content, [text(Text)|Rest]) :-
	next_input(T),
	code(T, N, Content, Rest).
@

## Writing Pandoc's Markdown
The writer is implemented as a single predicate, [[emit/1]], with one clause for each possible output, as produced by the finite state machine.
<<Emit Pandoc's markdown>>=
% TODO
:- multifile html_write:layout/3.
html_write:layout(pre, 0-0, 0-0).
html_write:layout(br, 0-0, 0-0).

:- use_module(library(http/html_write)).

emit(code(C)) :-
	maplist(codechunk_html, C, Content),
	html(div([class=codechunk], pre(Content)), HTML, []),
	print_html(HTML).
emit(quote(Q)) :-
	maplist(quotedcode_html, Q, Content),
	html(span([class=quotedcode], code(Content)), HTML, []),
	print_html(HTML).

codechunk_html(nl, br([])).
codechunk_html(text(Text), Text).
codechunk_html(defn(Name),
		span(class=nwdefn,
			[&(lang), &(nbsp), \[Formatted], &(nbsp), &(rang), &(equiv)])) :-
	through_pandoc(html5, Name, Formatted).
codechunk_html(use(Name),
		span(class=nwuse,
		[&(lang), &(nbsp), \[Formatted], &(nbsp), &(rang)])) :-
	through_pandoc(html5, Name, Formatted).

through_pandoc(_To, Str, FStr) :-
	atomic_list_concat(L, "'", Str),
	atomic_list_concat(L, "'\\''", EscStr),
	atomic_list_concat(["echo '", EscStr, "' | pandoc -t html5"], Pandoc),
	format(user_error, "~w~n", [Pandoc]),
	setup_call_cleanup(
		process_create(path(bash), ['-c', Pandoc], [stdout(pipe(Out))]),
		read_rest(Out, F0),
		close(Out)),
	append(`<p>`, F1, F0),
	once(append(F2, `</p>\n`, F1)),
	atom_codes(FStr, F2),
	format(user_error, "~w~n", [FStr]).

read_rest(Stream, Rest) :-
	read_pending_input(Stream, Rest, Rest1),
	(	at_end_of_stream(Stream)
	->	Rest1 = []
	;	read_rest(Stream, Rest1)
	).

quotedcode_html(nl, br([])).
quotedcode_html(text(Text), Text).
quotedcode_html(use(Name), span(class=nwuse, [&(lang), &(nbsp), Name, &(nbsp), &(rang)])).
@

# Common definitions
All building block for `noweb` (front ends, filters, back ends) are usually installed in the same place:
<<`Noweb` location>>=
/usr/lib/noweb
@

The portable Bash shebang is, according to [Stack Overflow](http://stackoverflow.com/questions/10376206/preferred-bash-shebang):
<<Bash shebang>>=
#! /usr/bin/env bash
set -e
@
We also set the script to stop immediately at errors.

# References

